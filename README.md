# Multi-Armed Bandit Algorithms: E-Greedy, UCB, and Thompson Sampling

## Overview

The **multi-armed bandit (MAB)** problem is a classic scenario in reinforcement learning where an agent must choose between multiple options ("arms") with uncertain rewards, aiming to maximize its total reward over time. The challenge lies in balancing exploration (trying new arms to discover their rewards) and exploitation (choosing the best-known arm).

This project contains a Jupyter Notebook that implements and analyzes three popular algorithms for solving the MAB problem:
